{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cf4acd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os.path\n",
    "# It is common practice to shorten 'pandas' to 'pd' for \n",
    "# less typing when calling functions from the pandas library.\n",
    "import pandas as pd\n",
    "\n",
    "# In this part, I read in the data. The data is in several different files\n",
    "# which I would like to combine into one dataframe. \n",
    "\n",
    "df_participants = pd.read_csv(\"https://openneuro.org/crn/datasets/ds002785/snapshots/2.0.0/files/participants.tsv\",sep='\\t')\n",
    "df_subjects = pd.DataFrame()\n",
    "\n",
    "for i in range(1, len(df_participants)+1):\n",
    "    df_subject = pd.read_csv(\"https://openneuro.org/crn/datasets/ds002785/snapshots/2.0.0/files/sub-\"+ str(i).zfill(4) +\":func:sub-\"+ str(i).zfill(4) +\"_task-emomatching_acq-seq_events.tsv\",sep='\\t')\n",
    "    # Some participants never did the emotion matching task so there is no csv at the link above.\n",
    "    # In this case the length of the dataframe df_subject is 0. \n",
    "    if (len(df_subject) != 0):\n",
    "        # Appends a column to the specific subject's data frame indicating what subject number they \n",
    "        # are in each row. This will be useful when all the subjects' data are put together in one\n",
    "        # dataframe so we can keep track of what data is connected to a given subject.\n",
    "        df_subject['subject'] = [i]*len(df_subject) \n",
    "        df_subjects = pd.concat([df_subjects, df_subject])\n",
    "df_subjects = df_subjects.reset_index()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07a23efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethn_distractor\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "# For each row checks that the data in each column takes the anticipated possible values.\n",
    "# If not the index at with the unanticipated data is printed and the loop stops.\n",
    "for index, row in df_subjects.iterrows():\n",
    "    # onset should either be NaN or a float\n",
    "    if (not (pd.isna(row['onset']) or isinstance(row['onset'], float))):\n",
    "        print('onset')\n",
    "        print(i)\n",
    "        break\n",
    "    # duration should either be NaN or a float\n",
    "    if (not (pd.isna(row['duration']) or isinstance(row['duration'], float))):\n",
    "        print('duration')\n",
    "        print(i)\n",
    "        break\n",
    "    # trial_type should either be NaN, control, or emotion\n",
    "    if (not (pd.isna(row['trial_type']) or (row['trial_type'] == 'control') or (row['trial_type'] == 'emotion'))):\n",
    "        print('trial_type')\n",
    "        print(i)\n",
    "        break\n",
    "    # response_time should either be NaN or a float\n",
    "    if (not (pd.isna(row['response_time']) or isinstance(row['response_time'], float))):\n",
    "        print('response_time')\n",
    "        print(i)\n",
    "        break\n",
    "    # response_hand should either be NaN, control, or emotion\n",
    "    if (not (pd.isna(row['response_hand']) or (row['response_hand'] == 'right') or (row['response_hand'] == 'left'))):\n",
    "        print('response_hand')\n",
    "        print(index)\n",
    "        break\n",
    "    # response_accuracy should either be NaN, correct, miss, or incorrect\n",
    "    if (not (pd.isna(row['response_accuracy']) or (row['response_accuracy'] == 'correct') or (row['response_accuracy'] == 'miss') or (row['response_accuracy'] == 'incorrect'))):\n",
    "        print('response_accuracy')\n",
    "        print(index)\n",
    "        break\n",
    "    # ori_match should either be NaN, vertical, or horizontal \n",
    "    if (not (pd.isna(row['ori_match']) or (row['ori_match'] == 'vertical') or (row['ori_match'] == 'horizontal'))):\n",
    "        print('ori_match')\n",
    "        print(index) \n",
    "        break\n",
    "    # sex should either be NaN, male, or female\n",
    "    if (not (pd.isna(row['sex']) or (row['sex'] == 'male') or (row['sex'] == 'female'))):\n",
    "        print('sex')\n",
    "        break\n",
    "    # ethn_target should either be NaN, caucasian, black, or asian\n",
    "    if (not (pd.isna(row['ethn_target']) or (row['ethn_target'] == 'caucasian') or (row['ethn_target'] == 'black') or (row['ethn_target'] == 'asian'))):\n",
    "        print('ethn_target')\n",
    "        print(index)\n",
    "        break\n",
    "    # ethn_match should either be NaN, caucasian, black, or asian\n",
    "    if (not (pd.isna(row['ethn_match']) or (row['ethn_match'] == 'caucasian') or (row['ethn_match'] == 'black') or (row['ethn_match'] == 'asian'))):\n",
    "        print('ethn_match')\n",
    "        print(index)\n",
    "        break\n",
    "    # emo_match should either be NaN, fear, or anger\n",
    "    if (not (pd.isna(row['emo_match']) or (row['emo_match'] == 'fear') or (row['emo_match'] == 'anger'))):\n",
    "        print('emo_match')\n",
    "        print(index)\n",
    "        break\n",
    "    # ethn_distractor should either be NaN, caucasian, black, or asian\n",
    "    if (not (pd.isna(row['ethn_distractor']) or (row['ethn_distractor'] == 'caucasian') or (row['ethn_distractor'] == 'black') or (row['ethn_distractor'] == 'asian'))):\n",
    "        print('ethn_distractor')\n",
    "        print(index)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63a0fa7",
   "metadata": {},
   "source": [
    "Per the paper describing the dataset (insert screen shot) there should not be an ethn_dsitractor variable. It is unclear where this variable came from. Moreover the documentation of the dataset in OpenNeuro (insert screen shots) says that the only levels of the variable are causasian, black, asian, or n/a. We can also see that the documentation is shotty for the emo_match variable. It says the levels are causasian, black, asian, or n/a when the paper says it is fear, anger, or n/a. We also see that the only column with unanticipated data is ethn_distractor. We therefore removed the ethn_distractor column as it should not have been there in the first place and will not contribute to our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e59b4a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>response_time</th>\n",
       "      <th>response_hand</th>\n",
       "      <th>response_accuracy</th>\n",
       "      <th>ori_match</th>\n",
       "      <th>sex</th>\n",
       "      <th>ethn_target</th>\n",
       "      <th>ethn_match</th>\n",
       "      <th>emo_match</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.0115</td>\n",
       "      <td>1.9212</td>\n",
       "      <td>control</td>\n",
       "      <td>1.9212</td>\n",
       "      <td>right</td>\n",
       "      <td>correct</td>\n",
       "      <td>vertical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15.0197</td>\n",
       "      <td>1.3478</td>\n",
       "      <td>control</td>\n",
       "      <td>1.3478</td>\n",
       "      <td>left</td>\n",
       "      <td>correct</td>\n",
       "      <td>vertical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20.0279</td>\n",
       "      <td>1.2605</td>\n",
       "      <td>control</td>\n",
       "      <td>1.2605</td>\n",
       "      <td>right</td>\n",
       "      <td>correct</td>\n",
       "      <td>horizontal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>25.0362</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>control</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>left</td>\n",
       "      <td>correct</td>\n",
       "      <td>horizontal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30.0444</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>control</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>right</td>\n",
       "      <td>correct</td>\n",
       "      <td>horizontal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10027</th>\n",
       "      <td>43</td>\n",
       "      <td>225.3638</td>\n",
       "      <td>4.9000</td>\n",
       "      <td>emotion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "      <td>asian</td>\n",
       "      <td>fear</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10028</th>\n",
       "      <td>44</td>\n",
       "      <td>230.3720</td>\n",
       "      <td>2.6348</td>\n",
       "      <td>emotion</td>\n",
       "      <td>2.6348</td>\n",
       "      <td>right</td>\n",
       "      <td>correct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>anger</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10029</th>\n",
       "      <td>45</td>\n",
       "      <td>235.3802</td>\n",
       "      <td>4.9000</td>\n",
       "      <td>emotion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>fear</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10030</th>\n",
       "      <td>46</td>\n",
       "      <td>240.3884</td>\n",
       "      <td>4.9000</td>\n",
       "      <td>emotion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>anger</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10031</th>\n",
       "      <td>47</td>\n",
       "      <td>245.3965</td>\n",
       "      <td>1.8188</td>\n",
       "      <td>emotion</td>\n",
       "      <td>1.8188</td>\n",
       "      <td>right</td>\n",
       "      <td>correct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>anger</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10032 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     onset  duration trial_type  response_time response_hand  \\\n",
       "0          0   10.0115    1.9212    control         1.9212         right   \n",
       "1          1   15.0197    1.3478    control         1.3478          left   \n",
       "2          2   20.0279    1.2605    control         1.2605         right   \n",
       "3          3   25.0362    0.9700    control         0.9700          left   \n",
       "4          4   30.0444    0.8287    control         0.8287         right   \n",
       "...      ...       ...       ...        ...            ...           ...   \n",
       "10027     43  225.3638    4.9000    emotion            NaN           NaN   \n",
       "10028     44  230.3720    2.6348    emotion         2.6348         right   \n",
       "10029     45  235.3802    4.9000    emotion            NaN           NaN   \n",
       "10030     46  240.3884    4.9000    emotion            NaN           NaN   \n",
       "10031     47  245.3965    1.8188    emotion         1.8188         right   \n",
       "\n",
       "      response_accuracy   ori_match     sex ethn_target ethn_match emo_match  \\\n",
       "0               correct    vertical     NaN         NaN        NaN       NaN   \n",
       "1               correct    vertical     NaN         NaN        NaN       NaN   \n",
       "2               correct  horizontal     NaN         NaN        NaN       NaN   \n",
       "3               correct  horizontal     NaN         NaN        NaN       NaN   \n",
       "4               correct  horizontal     NaN         NaN        NaN       NaN   \n",
       "...                 ...         ...     ...         ...        ...       ...   \n",
       "10027              miss         NaN  female       black      asian      fear   \n",
       "10028           correct         NaN    male   caucasian  caucasian     anger   \n",
       "10029              miss         NaN    male       black      black      fear   \n",
       "10030              miss         NaN  female   caucasian  caucasian     anger   \n",
       "10031           correct         NaN  female       asian      asian     anger   \n",
       "\n",
       "       subject  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "...        ...  \n",
       "10027      215  \n",
       "10028      215  \n",
       "10029      215  \n",
       "10030      215  \n",
       "10031      215  \n",
       "\n",
       "[10032 rows x 13 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subjects = df_subjects.drop('ethn_distractor',axis = 1)\n",
    "\n",
    "# Discuss how to deal with missing data MCAR, MAR etc.\n",
    "# Check if missing data is always paired correctly. The data might not truly be missing it \n",
    "# could simply that there is no sex when no face is present. Perhaps recode this to none instead of NaN.\n",
    "df_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad560fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
